No PMIx server was reachable, but a PMI1/2 was detected.
If srun is being used to launch application,  2 singletons will be started.
[nid003712:1568200] shmem: mmap: an error occurred while determining whether or not /tmp/ompi.nid003712.105387/jf.0/1498808320/shared_mem_cuda_pool.nid003712 could be created.
[nid003712:1568200] create_and_attach: unable to create shared memory BTL coordinating structure :: size 134217728 
[nid003900:350737] shmem: mmap: an error occurred while determining whether or not /tmp/ompi.nid003900.105387/jf.0/3653107712/shared_mem_cuda_pool.nid003900 could be created.
[nid003900:350737] create_and_attach: unable to create shared memory BTL coordinating structure :: size 134217728 
/global/homes/s/seanjx/.conda/envs/gigajax/lib/python3.12/site-packages/mpi4jax/_src/decorators.py:60: UserWarning: Not using CUDA-enabled MPI. If you are sure that your MPI library is built with CUDA support, set MPI4JAX_USE_CUDA_MPI=1. To silence this warning, set MPI4JAX_USE_CUDA_MPI=0.
  warnings.warn(warn_msg)
/global/homes/s/seanjx/.conda/envs/gigajax/lib/python3.12/site-packages/mpi4jax/_src/decorators.py:60: UserWarning: Not using CUDA-enabled MPI. If you are sure that your MPI library is built with CUDA support, set MPI4JAX_USE_CUDA_MPI=1. To silence this warning, set MPI4JAX_USE_CUDA_MPI=0.
  warnings.warn(warn_msg)
r0 | MPI_Send returned error code 6: b'MPI_ERR_RANK: invalid rank' - aborting
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD
  Proc: [[22870,0],0]
  Errorcode: 6

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
2024-07-26 21:08:07.867219: W external/tsl/tsl/distributed_runtime/preemption/preemption_sync_manager.cc:170] Failed to retrieve preemption notice from coordination service: UNAVAILABLE: Socket closed
Additional GRPC error information from remote target unknown_target_for_coordination_leader while calling /tensorflow.CoordinationService/GetKeyValue:
:UNKNOWN:Error received from peer  {created_time:"2024-07-26T21:08:07.866703939-07:00", grpc_status:14, grpc_message:"Socket closed"}. This is only expected if one of the tasks is unhealthy. Check the logs for the actual root cause.
2024-07-26 21:08:07.867758: E external/tsl/tsl/distributed_runtime/preemption/preemption_sync_manager.cc:182] Failed to cancel preemption barrier: UNAVAILABLE: failed to connect to all addresses; last error: UNKNOWN: ipv4:128.55.68.101:63677: Failed to connect to remote host: Connection refused
Additional GRPC error information from remote target unknown_target_for_coordination_leader while calling /tensorflow.CoordinationService/CancelBarrier:
:UNKNOWN:Error received from peer  {created_time:"2024-07-26T21:08:07.867722742-07:00", grpc_status:14, grpc_message:"failed to connect to all addresses; last error: UNKNOWN: ipv4:128.55.68.101:63677: Failed to connect to remote host: Connection refused"}
srun: error: nid003712: task 0: Exited with exit code 6
srun: Terminating StepId=28637373.0
2024-07-26 21:08:11.892221: W external/tsl/tsl/distributed_runtime/preemption/preemption_notifier.cc:89] SIGTERM caught at 2024-07-26T21:08:11.892168838-07:00
srun: error: nid003900: task 1: Killed
srun: Force Terminated StepId=28637373.0
