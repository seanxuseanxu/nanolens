2024-08-06 17:53:48.534201: W external/xla/xla/service/gpu/nvptx_compiler.cc:765] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.5.82). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.
246_2024-08-06 17:53:45.833809
-0.43668595
20 (['EPL', 'SHEAR'], ['SERSIC_ELLIPSE'], ['SERSIC_ELLIPSE'])
  0%|                                                                                                                                                                                                    | 0/1000 [00:00<?, ?it/s]2024-08-06 17:54:04.094104: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng36{k2=5,k13=1,k14=3,k18=1,k23=0} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:05.024136: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.930116732s
Trying algorithm eng36{k2=5,k13=1,k14=3,k18=1,k23=0} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:06.024238: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng35{k2=1,k5=2,k14=5} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:06.643588: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.619408908s
Trying algorithm eng35{k2=1,k5=2,k14=5} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:07.643671: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=4,k5=2,k14=3} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:07.860666: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.217048039s
Trying algorithm eng46{k2=4,k5=2,k14=3} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:08.860786: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=7,k5=3,k14=2} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:12.735650: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 4.874952663s
Trying algorithm eng46{k2=7,k5=3,k14=2} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:13.909925: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=5,k5=3,k14=4} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:16.633298: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.723466744s
Trying algorithm eng46{k2=5,k5=3,k14=4} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:17.984214: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=1,k5=3,k14=2} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:20.043746: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 3.059573862s
Trying algorithm eng46{k2=1,k5=3,k14=2} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:21.110749: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng46{k2=0,k5=2,k14=3} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:21.921504: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.810848047s
Trying algorithm eng46{k2=0,k5=2,k14=3} for conv (f32[16000,2,60,60]{3,2,1,0}, u8[0]{0}) custom-call(f32[16000,2,60,60]{3,2,1,0}, f32[2,1,13,13]{3,2,1,0}), window={size=13x13 pad=6_6x6_6}, dim_labels=bf01_oi01->bf01, feature_group_count=2, custom_call_target="__cudnn$convForward", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"conv_result_scale":1,"activation_mode":"kNone","side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false} is taking a while...
2024-08-06 17:54:22.887690: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below 28.06GiB (30134493183 bytes) by rematerialization; only reduced to 47.76GiB (51284523448 bytes), down from 49.26GiB (52897323816 bytes) originally
2024-08-06 17:54:36.318469: W external/xla/xla/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_0_bfc) ran out of memory trying to allocate 48.30GiB (rounded to 51860487680)requested by op 
2024-08-06 17:54:36.318693: W external/xla/xla/tsl/framework/bfc_allocator.cc:494] **__________________________________________________________________________________________________
E0806 17:54:36.318718 2018787 pjrt_stream_executor_client.cc:2985] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 51860487528 bytes.
2024-08-06 17:54:36.377451: W external/xla/xla/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_1_bfc) ran out of memory trying to allocate 48.30GiB (rounded to 51860487680)requested by op 
2024-08-06 17:54:36.377538: W external/xla/xla/tsl/framework/bfc_allocator.cc:494] *___________________________________________________________________________________________________
E0806 17:54:36.377553 2018789 pjrt_stream_executor_client.cc:2985] Execution of replica 1 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 51860487528 bytes.
2024-08-06 17:54:36.432279: W external/xla/xla/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_2_bfc) ran out of memory trying to allocate 48.30GiB (rounded to 51860487680)requested by op 
2024-08-06 17:54:36.432380: W external/xla/xla/tsl/framework/bfc_allocator.cc:494] *___________________________________________________________________________________________________
E0806 17:54:36.432395 2018791 pjrt_stream_executor_client.cc:2985] Execution of replica 2 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 51860487528 bytes.
2024-08-06 17:54:36.497803: W external/xla/xla/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_3_bfc) ran out of memory trying to allocate 48.30GiB (rounded to 51860487680)requested by op 
2024-08-06 17:54:36.497903: W external/xla/xla/tsl/framework/bfc_allocator.cc:494] *___________________________________________________________________________________________________
E0806 17:54:36.497918 2018793 pjrt_stream_executor_client.cc:2985] Execution of replica 3 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 51860487528 bytes.
  0%|                                                                                                                                                                                                    | 0/1000 [00:44<?, ?it/s]
Traceback (most recent call last):
  File "/global/homes/s/seanjx/gigalens/testetc/nanolensNOparallelization.py", line 105, in <module>
    map_estimate, chi = model_seq.MAP(opt, n_samples=n_samples_bs,num_steps=1000,seed=0)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/s/seanjx/gigalens/src/gigalens/jax/inference.py", line 67, in MAP
    loss, params, opt_state = update(params, opt_state)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/s/seanjx/gigalens/src/gigalens/jax/inference.py", line 56, in update
    (_, chisq), grads = loss_and_grad(splt_params)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 51860487528 bytes.: while running replica 0 and partition 0 of a replicated computation (other replicas may have failed as well).
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
srun: error: nid003256: task 0: Exited with exit code 1
srun: Terminating StepId=29126958.0
